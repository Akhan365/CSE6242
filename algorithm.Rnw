\documentclass[a4paper]{article}

\title{%
  CSE 6242 - Data and Visual Analytics \\
  HW3: Logistic Regression}
\author{Ebeid ElSayed - Ebeid@gatech.edu}

\usepackage[linesnumbered,lined,boxed,commentsnumbered]{algorithm2e} 
\usepackage { Sweave }

\begin{document}
\SweaveOpts{concordance=TRUE}

\maketitle
\setcounter{secnumdepth}{0}

\section{0. Data Preprocessing}

$a. Download the CSV files for the provided dataset.\\$ 
$b. Read mnist_train.csv and mnist_test.csv separately.$

<<>>=

setwd("C:/Users/eelsayed/Google Drive/CSE6242")
rawDatalLoaded <- TRUE

if(file.exists("mnist_train.csv")){
  train <- read.csv(file="mnist_train.csv", header = FALSE)
}else{
  rawDatalLoaded <- FALSE
}

if(file.exists("mnist_test.csv")){
  test <- read.csv(file="mnist_test.csv", header = FALSE)
}else{
  rawDatalLoaded <- FALSE
}

if(!rawDatalLoaded){
  print("Data wasn't loaded correctly.")
}

train <- as.data.frame(t(train))
names(train)[785] <- "Label"

test <- as.data.frame(t(test))
names(test)[785] <- "Label"

@

$c. Partition the training set for classification of 0, 1 and 3, 5 classes based on the class label (last row 785): train_0_1, train_3_5.$

<<>>=
train_0_1 <- train[(train$Label == 0) | (train$Label == 1),]
train_3_5 <- train[(train$Label == 3) | (train$Label == 5),]
@

$d. Do the same for the test set: test_0_1, test_3_5.$

<<>>=
test_0_1 <- test[(test$Label == 0) | (test$Label == 1),]
test_3_5 <- test[(test$Label == 3) | (test$Label == 5),]
@

$e & f Separate the class label from all the partitions created (remove row 785 from the actual data and store it \\as a separate vector).$

<<>>=
true_label_train_0_1 <- train_0_1$Label
train_0_1 <- subset(train_0_1, select = names(train_0_1) != "Label" )

true_label_train_3_5 <- train_3_5$Label
train_3_5 <- subset(train_3_5, select = names(train_3_5) != "Label" )

true_label_test_0_1 <- test_0_1$Label
test_0_1 <- subset(test_0_1, select = names(test_0_1) != "Label" )

true_label_test_3_5 <- test_3_5$Label
test_3_5 <- subset(test_3_5, select = names(test_3_5) != "Label" )
@

$g. Visualize 1 image from each class to ensure you have read in the data correctly.$

<<g, results=hide>>=
save_digit_image <- function(df, digitClass, imageTitle, fileName) {
  tmp <- df[df$Label == digitClass,]
  m <- matrix(unlist(tmp[1,1:784]), ncol = 28, byrow = TRUE)
  
  jpeg(filename = fileName)
  image(z = m, col = gray.colors(256))
  title(main = imageTitle)
  dev.off()
}
save_digit_image(train, 0, "Class label : 0", "0.jpg")
save_digit_image(train, 1, "Class label : 1", "1.jpg")
save_digit_image(train, 3, "Class label : 3", "3.jpg")
save_digit_image(train, 5, "Class label : 5", "5.jpg")
@

\includegraphics{0.jpg} \\
\includegraphics{1.jpg} \\
\includegraphics{3.jpg} \\
\includegraphics{5.jpg} \\

\setcounter{secnumdepth}{1}

\section{Theory}

\textbf{a} Write down the formula for computing the gradient of the loss function used in Logistic Regression. Specify what each variable represents in the equation.\\

The formula for the gradient descent is:
\[
\theta_j \leftarrow \theta_j - \alpha \sum_{i=1}^{n} \frac{1}{1 + \exp(-y^{(i)} <\theta, x^{(i)}> )}
\]
where $x^{(i)}$ is the data point represented in a vector of features, $y^{(i)}$ is the class label, and $\theta$ is the parameter vector. The goal is to reach the $\theta$ that maximizes our likelihood function (given the data we use to train the model).\\

\textbf{b} Write pseudocode for training a model using Logistic Regression.\\

\SetEndCharOfAlgoLine{}

\begin{algorithm}[H]
 \KwData{Training data}
 convergence threshold: $\eta$\;
 step size: $\alpha$\;
 \For{$j\leftarrow 0$ \KwTo $d$}{
  initialize $\theta_j$\;
  initialize $\Delta\theta_j$\;
 }
 
  \For{$i\leftarrow 1$ \KwTo $n$}{
  $x_0^{(i)} = 1$\;
 }
 \While{$\cup_{j\in\{0,1,...,d\}}|\delta\theta_j/\theta_j|>\eta$}{
    \For{$i\leftarrow 1$ \KwTo $n$}{
      $z^{(i)} = \sum_{j=0}^{d} \theta_j x_j^{(i)} $\;
      }
    \For{$j\leftarrow 0$ \KwTo $d$}{
      $\Delta = 0$\;
        \For{$i\leftarrow 1$ \KwTo $n$}{
            $\Delta \leftarrow \Delta + \frac{y^{(i)} x_j^{(i)}}{1 + \exp(-y^{(i)} z^{(i)} )}$\;
          }
      }
      $\theta_j \leftarrow $\theta_j - \alpha\Delta$\;
      $\delta\theta_j = \alpha\Delta$\;
 }
  \Return $\{\theta_0,...,\theta_d\}$\;
\end{algorithm}\DecMargin{1em}

\textbf{c} Calculate the number of operations per gradient descent iteration.\\
Each gradient descent update iteration requires $2n(d + 1)$\\

\section{Implementation}
<<>>=
# Gredient Descent
gradient_descent <- function(X, Y, XY, theta){
    z <- as.matrix(X) %*% theta
    yz_exp <- 1 / (1 + exp(-Y * z))
    # Precalculate that instead for performance
    #tmp <- apply(X,2,function(x) X * Y)
    delta_theta <- t(XY) %*% yz_exp
    return(delta_theta)
}

# Logistic Regression
# threshold should be higher than 100 but I used 100 by default to speed up the calculations need for the report
logistic_regression <- function(X, Y, deviation, alpha, eta, seed = 100, threshold = 100) {
  # initializations
  set.seed(seed)
  X$intercept <- 1
  theta <- rnorm(ncol(X), sd = deviation)
  delta_theta <- rep(10000, ncol(X))
  numIterations <- 1
  
  #XY <- apply(X,2,function(x) X * Y)
  XY <- sweep(X, 1,Y, "*")
  while (any(abs(alpha * delta_theta/(theta + 0.0001)) > eta) & numIterations < threshold){
    delta_theta <- gradient_descent(X,Y, XY,theta)
    theta <- theta - alpha * delta_theta
    numIterations <- numIterations + 1
  }
  return(theta)
}
@

\section{Training}
\textbf{a} Train 2 models, one on the train_0_1 set and another on train_3_5, and report the\\
training and test accuracies.
<<>>=
# Calculate the predictions
predict <- function(thetasFromTraining, classLabel){
  classLabel$intercept <- 1
  -sign(as.matrix(classLabel) %*% thetasFromTraining)
}

# Calculate the accuracy
accuracy <- function(model_function, X, Y, deviation, alpha = 0.001, eta = 0.000001, seed = 100, threshold = 100){
  model_output <- model_function(X, Y, deviation, alpha, eta, seed, threshold)
  a <- predict(model_output, X)
  tmp <- mean(Y == a)
  return(tmp)
}

theta <- rnorm(ncol(train_0_1), sd = 0.5)
accuracy(logistic_regression, train_0_1, true_label_train_0_1, deviation = 0.5)
accuracy(logistic_regression, train_3_5, true_label_train_3_5, deviation = 0.5)
@

\textbf{b} Repeat 3a 10 times, i.e. you should obtain 10 train and test accuracies for each set.
Calculate the average train and test accuracies over the 10 runs, and report them.

<<>>=

train_0_1_accuracies <- numeric()
for(i in 1:10){ 
  train_0_1_accuracies <- append(train_0_1_accuracies, accuracy(logistic_regression, train_0_1, true_label_train_0_1, deviation = 0.5 ))
}
mean(train_0_1_accuracies)

train_3_5_accuracies <- numeric()
for(i in 1:10){ 
  train_3_5_accuracies <- append(train_3_5_accuracies, accuracy(logistic_regression, train_3_5, true_label_train_3_5, deviation = 0.5))
}
mean(train_3_5_accuracies)


test_0_1_accuracies <- numeric()
for(i in 1:10){
 test_0_1_accuracies <- append(test_0_1_accuracies, accuracy(logistic_regression, test_0_1, true_label_test_0_1, deviation = 0.5)) 
}
mean(test_0_1_accuracies)

test_3_5_accuracies <- numeric()
for(i in 1:10){
  test_3_5_accuracies <- append(test_3_5_accuracies, accuracy(logistic_regression, test_3_5, true_label_test_3_5, deviation = 0.5))
}
mean(test_3_5_accuracies)

@

\textbf{c} For 0,1 and 3,5 cases, explain if you observe any difference you in accuracy. Also,\\
explain why do you think this difference might be.\\

\textbf{d} This assignment deals with binary classification. Explain what you would do if you \\
had more than two classes to classify, using logistic regression.\\
Since logistic regression can only classify into two classes, I will use N-1 logistic regression\\ 
models where N is the number of outcome classes we have. Each model $m_i$ will classify  each un-classified \\
observation into two outcomes: wether the observation falls in class $n_i$ or not. By running these models \\
in sequence, the number of un-classified observations will get reduced untill we have all observations \\
getting classified by one of the models, or remain un-classified.

\section{Evaluation}

\textbf{a} Experiment with different initializations of the parameter used for gradient descent \\
Clearly mention the initial values of the parameter tried, run the same experiment \\
as 3b using this initialization, report the average test and train accuracies obtained \\
by using this initialization, mention which is set of initializations is the better.\\

\textbf{initial_parameters_baseline} : 

\begin{itemize}
  \item theta = rnorm(ncol(train_0_1), sd = 0.5)
  \item alpha = 0.001
  \item eta = 0.000001
  \item threshold = 100 (Threshold should be higher than 100 but I used 100 by default to speed up the calculations needed for the report.)
\end{itemize}

\textbf{convergence_criteria_baseline} : (abs(alpha * delta_theta/(theta + 0.0001)) > eta) OR (numIterations < threshold) \\

Changing the initial parameters and keeping the convergence criteria the same. I obtained a new initial theta by changing the standard deviation I used for generating it.

<<>>=
train_0_1_accuracies <- numeric()
t <- rnorm(ncol(train_0_1), sd = 0.7)
for(i in 1:10){ 
  train_0_1_accuracies <- append(train_0_1_accuracies, 
                                 accuracy(logistic_regression, 
                                          train_0_1, true_label_train_0_1, 
                                          deviation = 0.7
                                          )
                                 )
}
mean(train_0_1_accuracies)

train_3_5_accuracies <- numeric()
for(i in 1:10){ 
  train_3_5_accuracies <- append(train_3_5_accuracies, accuracy(logistic_regression, train_3_5, true_label_train_3_5, deviation = 0.7))
}
mean(train_3_5_accuracies)


test_0_1_accuracies <- numeric()
for(i in 1:10){
 test_0_1_accuracies <- append(test_0_1_accuracies, accuracy(logistic_regression, test_0_1, true_label_test_0_1, deviation = 0.7)) 
}
mean(test_0_1_accuracies)

test_3_5_accuracies <- numeric()
for(i in 1:10){
  test_3_5_accuracies <- append(test_3_5_accuracies, accuracy(logistic_regression, test_3_5, true_label_test_3_5, deviation = 0.7))
}
mean(test_3_5_accuracies)
@

\textbf{b} Experiment with different convergence criteria for gradient descent. Clearly mention \\
the new criteria tried, run the same experiment as 3b using this new criteria, report \\
average test and train accuracies obtained using this criteria, mention which set of \\
criteria is better. \\

Changing the convergence critiera and keeping the initial parameters the same.
\textbf{new_convergence_criteria} : (abs(alpha * delta_theta/(theta + 0.0001)) > eta) OR (numIterations < threshold) . Where: \\
\begin{itemize}
  \item theta = rnorm(ncol(train_0_1), sd = 0.5). Same as initial_parameters_baseline.
  \item alpha = 0.01
  \item eta = 0.0001
  \item threshold = 1000
\end{itemize}

<<>>=
train_0_1_accuracies <- numeric()
for(i in 1:10){ 
  train_0_1_accuracies <- append(train_0_1_accuracies, accuracy(logistic_regression, train_0_1, true_label_train_0_1, deviation = 0.5, alpha = 0.01, eta = 0.0001, threshold = 1000))
}
mean(train_0_1_accuracies)

train_3_5_accuracies <- numeric()
for(i in 1:10){ 
  train_3_5_accuracies <- append(train_3_5_accuracies, accuracy(logistic_regression, train_3_5, true_label_train_3_5, deviation = 0.5, alpha = 0.01, eta = 0.0001, threshold = 1000))
}
mean(train_3_5_accuracies)


test_0_1_accuracies <- numeric()
for(i in 1:10){
 test_0_1_accuracies <- append(test_0_1_accuracies, accuracy(logistic_regression, test_0_1, true_label_test_0_1, deviation = 0.5, alpha = 0.01, eta = 0.0001, threshold = 1000)) 
}
mean(test_0_1_accuracies)

test_3_5_accuracies <- numeric()
for(i in 1:10){
  test_3_5_accuracies <- append(test_3_5_accuracies, accuracy(logistic_regression, test_3_5, true_label_test_3_5, deviation = 0.5, alpha = 0.01, eta = 0.0001, threshold = 1000))
}
mean(test_3_5_accuracies)
@

\section{Evaluation}
\textbf(a)

<<>>=
# Calculate the accuracy for samples of divisions in the training data using the passed cutRatio
accuracy <- function(model_function, X, Y, deviation, cutRatio, divisions = 10, alpha = 0.001, eta = 0.000001, seed = 100, threshold = 100){
  set.seed(seed)
  samples <- lapply(1:divisions, function(division){
    sample(1:nrow(X), round(cutRatio * nrow(X)))
    })
  
  samplesAccuracies <- sapply(samples, function(s){
    X <- X[sa,]
    Y <- as.data.frame(Y)
    Y <- Y[sa,]
    
    model_output <- model_function(X, Y, deviation, alpha, eta, seed, threshold)
    a <- predict(model_output, X)
    mean(Y == a)
  })
  
  return(mean(samplesAccuracies))
}

train_0_1_Splits_Accuracies <- data.frame(Split = double(), Accuracy = double())
for(i in 1:20)
{
  train_0_1_Splits_Accuracies <- rbind(train_0_1_Splits_Accuracies,
                                       data.frame(
                                         i/10,
                                         accuracy(logistic_regression, train_0_1, true_label_train_0_1, deviation = 0.5, cutRatio = i/10 )) 
                                       )
}

train_3_5_Splits_Accuracies <- data.frame(Split = double(), Accuracy = double())
for(i in 1:20)
{
  train_3_5_Splits_Accuracies <- rbind(train_3_5_Splits_Accuracies,
                                       data.frame(
                                         i/10,
                                         accuracy(logistic_regression, train_3_5, true_label_train_3_5, deviation = 0.5, cutRatio = i/10 )) 
                                       )
}

test_0_1_Splits_Accuracies <- data.frame(Split = double(), Accuracy = double())
for(i in 1:20)
{
  test_0_1_Splits_Accuracies <- rbind(test_0_1_Splits_Accuracies,
                                       data.frame(
                                         i/10,
                                         accuracy(logistic_regression, test_0_1, true_label_test_0_1, deviation = 0.5, cutRatio = i/10 )) 
                                       )
}

test_3_5_Splits_Accuracies <- data.frame(Split = double(), Accuracy = double())
for(i in 1:20)
{
  test_3_5_Splits_Accuracies <- rbind(test_3_5_Splits_Accuracies,
                                       data.frame(
                                         i/10,
                                         accuracy(logistic_regression, test_3_5, true_label_test_3_5, deviation = 0.5, cutRatio = i/10 )) 
                                       )
}
@


\end{document}